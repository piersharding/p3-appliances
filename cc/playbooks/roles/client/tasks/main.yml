---

- name: Ensure required packages are installed (apt)
  apt:
    name: "{{ item }}"
    update_cache: yes
    state: installed
  with_items:
  - python-pip
  - python3-pip

- name: set server id
  set_fact:
    this_server_id: "{{ play_hosts.index(inventory_hostname) + 1 }}"

- name: download https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-5.3.1-amd64.deb
  get_url:
    url: https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-5.3.1-amd64.deb
    dest: /var/tmp/metricbeat-5.3.1-amd64.deb

- name: Install /var/tmp/metricbeat-5.3.1-amd64.deb package
  apt:
    deb: /var/tmp/metricbeat-5.3.1-amd64.deb
  register: updatemetricbeat

# curl -G --data-urlencode 'match[]={job=~".+"}' http://10.111.1.11:9090/federate
# GET /federate?match[]=%7Bjob%3D~%22.%2B%22%7D HTTP/1.1

# - name: /etc/metricbeat/metricbeat.yml
#   copy:
#     content: |-
#       metricbeat.modules:
#       - module: docker
#         # metricsets: ["container", "cpu", "diskio", "healthcheck", "info", "memory", "network"]
#         metricsets: ["container", "cpu", "diskio", "info", "memory", "network"]
#         hosts: ["unix:///var/run/docker.sock"]
#         enabled: true
#         period: 10s

#       - module: system
#         metricsets:
#           # CPU stats
#           - cpu

#           # System Load stats
#           - load

#           # Per CPU core stats
#           - core

#           # IO stats
#           - diskio

#           # Per filesystem stats
#           - filesystem

#           # File system summary stats
#           - fsstat

#           # Memory stats
#           - memory

#           # Network stats
#           - network

#           # Per process stats
#           - process

#           # Sockets (linux only)
#           #- socket
#         enabled: true
#         period: 10s
#         processes: ['.*']

#       output.logstash:
#         # The Logstash hosts
#         hosts: ["{{ elastic_logstash1 }}:5044"]
#         index: metrics

#       logging.level: info

#       logging.selectors: ["*"]

#     force: yes
#     dest: /etc/metricbeat/metricbeat.yml
#   register: updatemetricbeat


# - name: ensure metricbeat restarts
#   service: name=metricbeat state=restarted enabled=yes
#   when: updatemetricbeat.changed
#   become: true

- name: install docker dependencies
  pip:
    name: docker-py

- name: nodes remove containers
  docker_container:
    name: "{{ item }}"
    state: absent
  with_items:
    - nodeexporter

- name: docker pull images
  docker_image:
    name: "{{ item.name }}"
    tag: "{{ item.tag }}"
    pull: true
    state: present
  with_items:
    - name: prom/node-exporter
      tag: latest

- name: Restart a nodeexporter
  docker_container:
    name: nodeexporter
    restart_policy: always
    image: "prom/node-exporter:latest"
    state: started
    network_mode: host
    command: --collector.textfile.directory /textfiles
    volumes:
     - "/var/lib/node_exporter/textfile_collector:/textfiles:ro"
    labels:
      org.label-schema.group: monitoring
    ports:
      - "9100:9100"



# install Prometheus

- name: prometheus remove containers
  docker_container:
    name: "{{ item }}"
    state: absent
  with_items:
    - prometheus
    - alertmanager
    - grafana

- name: Creates directory /var/lib/prometheus-data
  file: path=/var/lib/prometheus-data state=directory mode=0777

- name: Creates directory /etc/prometheus/static_configs
  file: path=/etc/prometheus/static_configs state=directory

- name: /etc/prometheus/prometheus.yml
  copy:
    content: |-
      global:
        scrape_interval:     5s
        evaluation_interval: 5s

        # Attach these labels to any time series or alerts when communicating with
        # external systems (federation, remote storage, Alertmanager).
        external_labels:
            monitor: 'docker-master'

      # Load and evaluate rules in this file every 'evaluation_interval' seconds.
      rule_files:
        - "targets.rules"
        - "host.rules"
        - "containers.rules"

      # A scrape configuration containing exactly one endpoint to scrape.
      scrape_configs:
        # - job_name: 'qpid'
        #   static_configs:
        #    - targets:
        #      - 10.101.1.188:9100
        #      - 10.101.1.189:9100
        #      - 10.101.1.190:9100
        - job_name: 'nodeexporter'
          static_configs:
           - targets:
             - cc-node-0:9100
        - job_name: 'dockermetrics'
          static_configs:
           - targets:
             - cc-node-0:9323
        - job_name: 'cadvisor'
          static_configs:
           - targets:
             - cc-node-0:8081
        - job_name: 'pexporter'
          static_configs:
           - targets:
             - cc-node-0:9256

        # - job_name: 'elasticsearch'
        #   metrics_path: "/_prometheus/metrics"
        #   static_configs:
        #    - targets:
        #      - 10.101.1.158:9200

        # - job_name: 'logstash'
        #   static_configs:
        #    - targets:
        #      - 10.128.26.15:1234
        #      - 10.128.26.15:1235


        #- job_name: 'nodeexporter'
        #  scrape_interval: 5s
        #  # static_configs:
        #  #   - targets: ['nodeexporter:9100']
        #  file_sd_configs:
        #      - files:
        #          - /etc/prometheus/static_configs/nodeexporter*.yaml
        #      # - refresh_interval: 1m

        #- job_name: 'cadvisor'
        #  scrape_interval: 5s
        #  # static_configs:
        #  #   - targets: ['cadvisor:8080']
        #  file_sd_configs:
        #      - files:
        #          - /etc/prometheus/static_configs/cadvisor*.yaml
        #      # - refresh_interval: 1m

        #- job_name: 'docker'
        #  scrape_interval: 5s
        #  # static_configs:
        #  #   - targets: ['docker:9323']
        #  file_sd_configs:
        #      - files:
        #          - /etc/prometheus/static_configs/docker*.yaml
        #      # - refresh_interval: 1m

        #- job_name: 'process'
        #  scrape_interval: 5s
        #  # static_configs:
        #  #   - targets: ['docker:9323']
        #  file_sd_configs:
        #      - files:
        #          - /etc/prometheus/static_configs/process*.yaml
        #      # - refresh_interval: 1m

      #  - job_name: 'masternode'
      #    scrape_interval: 5s
      #    static_configs:
      #      - targets: ['kafka-master-0:8000']

        - job_name: 'prometheus'
          scrape_interval: 10s
          static_configs:
            - targets: ['localhost:9090']

      #  - job_name: 'nginx'
      #    scrape_interval: 10s
      #    static_configs:
      #      - targets: ['nginxexporter:9113']
    force: yes
    dest: /etc/prometheus/prometheus.yml
  register: updateprometheus


- name: /etc/prometheus/containers.rules
  copy:
    content: |-
      # ALERT jenkins_down
      #   IF absent(container_memory_usage_bytes{name="jenkins"})
      #   FOR 30s
      #   LABELS { severity = "critical" }
      #   ANNOTATIONS {
      #     summary= "Jenkins down",
      #     description= "Jenkins container is down for more than 30 seconds."
      #   }

      #  ALERT jenkins_high_cpu
      #   IF sum(rate(container_cpu_usage_seconds_total{name="jenkins"}[1m])) / count(node_cpu{mode="system"}) * 100 > 10
      #   FOR 30s
      #   LABELS { severity = "warning" }
      #   ANNOTATIONS {
      #     summary= "Jenkins high CPU usage",
      #     description= "Jenkins CPU usage is {{ '{{' }} humanize $value{{ '}}' }}%."
      #   }

      # ALERT jenkins_high_memory
      #   IF sum(container_memory_usage_bytes{name="jenkins"}) > 1200000000
      #   FOR 30s
      #   LABELS { severity = "warning" }
      #   ANNOTATIONS {
      #       summary = "Jenkins high memory usage",
      #       description = "Jenkins memory consumption is at {{ '{{' }} humanize $value{{ '}}' }}.",
      # }
    force: yes
    dest: /etc/prometheus/containers.rules
  register: updateprometheus

- name: /etc/prometheus/host.rules
  copy:
    content: |-
      # ALERT high_cpu_load
      #   IF node_load1 > 1.5
      #   FOR 30s
      #   LABELS { severity = "warning" }
      #   ANNOTATIONS {
      #       summary = "Server under high load",
      #       description = "Docker host is under high load, the avg load 1m is at {{ '{{' }} $value{{ '}}' }}. Reported by instance {{ '{{' }} $labels.instance {{ '}}' }} of job {{ '{{' }} $labels.job {{ '}}' }}.",
      #   }

      # ALERT high_memory_load
      #   IF (sum(node_memory_MemTotal) - sum(node_memory_MemFree + node_memory_Buffers + node_memory_Cached) ) / sum(node_memory_MemTotal) * 100 > 85
      #   FOR 30s
      #   LABELS { severity = "warning" }
      #   ANNOTATIONS {
      #       summary = "Server memory is almost full",
      #       description = "Docker host memory usage is {{ '{{' }} humanize $value{{ '}}' }}%. Reported by instance {{ '{{' }} $labels.instance {{ '}}' }} of job {{ '{{' }} $labels.job {{ '}}' }}.",
      #   }

      # ALERT hight_storage_load
      #   IF (node_filesystem_size{fstype="aufs"} - node_filesystem_free{fstype="aufs"}) / node_filesystem_size{fstype="aufs"}  * 100 > 85
      #   FOR 30s
      #   LABELS { severity = "warning" }
      #   ANNOTATIONS {
      #       summary = "Server storage is almost full",
      #       description = "Docker host storage usage is {{ '{{' }} humanize $value{{ '}}' }}%. Reported by instance {{ '{{' }} $labels.instance {{ '}}' }} of job {{ '{{' }} $labels.job {{ '}}' }}.",
      # }
    force: yes
    dest: /etc/prometheus/host.rules
  register: updateprometheus

- name: /etc/prometheus/targets.rules
  copy:
    content: |-
      # ALERT monitor_service_down
      #   IF up == 0
      #   FOR 30s
      #   LABELS { severity = "critical" }
      #   ANNOTATIONS {
      #       summary = "Monitor service non-operational",
      #       description = "Service {{ '{{' }} $labels.instance {{ '}}' }} is down.",
      #   }
    force: yes
    dest: /etc/prometheus/targets.rules
  register: updateprometheus

- name: Update node_export config
  blockinfile: dest=/etc/prometheus/static_configs/nodeexporter.yaml block="{{ lookup('file', './prometheus_nodeexporter.yaml') }}"
              state=present create=yes
  register: updateconfig
  become: true

- name: Update cadvisor config
  blockinfile: dest=/etc/prometheus/static_configs/cadvisor.yaml block="{{ lookup('file', './prometheus_cadvisor.yaml') }}"
              state=present create=yes
  register: updateconfig
  become: true

- name: Update docker config
  blockinfile: dest=/etc/prometheus/static_configs/docker.yaml block="{{ lookup('file', './prometheus_docker.yaml') }}"
              state=present create=yes
  register: updateconfig
  become: true

- name: Update process config
  blockinfile: dest=/etc/prometheus/static_configs/process.yaml block="{{ lookup('file', './prometheus_process.yaml') }}"
              state=present create=yes
  register: updateconfig
  become: true

# - name: ensure Prometheus restarts
#   shell: /usr/bin/docker restart prometheus
#   when: updateconfig.changed
#   become: true

- name: Creates directory /var/lib/prometheus-data/prometheus
  file: path=/var/lib/prometheus-data/prometheus state=directory mode=0777

- name: docker pull images
  docker_image:
    state: present
    pull: true
    name: "{{ item }}"
  with_items:
    - prom/prometheus:latest
    - prom/alertmanager:latest
    - grafana/grafana:latest

- name: Restart a Prometheus
  docker_container:
    name: prometheus
    restart_policy: always
    image: prom/prometheus:latest
    # command: "--config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus-data --alertmanager.url=http://alertmanager-url:9093 --storage.local.memory-chunks=10000000"
    command: "--config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus-data --web.listen-address=0.0.0.0:9090 "
    state: started
    labels:
      org.label-schema.group: monitoring
    volumes:
     - "/var/lib/prometheus-data/prometheus:/prometheus-data"
     - "/etc/prometheus:/etc/prometheus"
    ports:
    - "9090:9090"

- name: Creates directory /etc/alertmanager/template
  file: path=/etc/alertmanager/template state=directory

- name: /etc/alertmanager/config.yml
  copy:
    content: |-
      # route:
      #     receiver: 'slack'

      # receivers:
      #     - name: 'slack'
      #       slack_configs:
      #           - send_resolved: true
      #             text: "{{ '{{' }} .CommonAnnotations.description {{ '}}' }}"
      #             username: 'Prometheus'
      #             channel: '#<channel-name>'
      # api_url: 'https://hooks.slack.com/services/<webhook-id>'
      global:
        # The smarthost and SMTP sender used for mail notifications.
        smtp_smarthost: 'localhost:25'
        smtp_from: 'alertmanager@example.org'
        smtp_auth_username: 'alertmanager'
        smtp_auth_password: 'password'
        # The auth token for Hipchat.
        # hipchat_auth_token: '1234556789'
        # Alternative host for Hipchat.
        # hipchat_url: 'https://hipchat.foobar.org/'

      # The directory from which notification templates are read.
      templates:
      - '/etc/alertmanager/template/*.tmpl'

      # The root route on which each incoming alert enters.
      route:
        # The labels by which incoming alerts are grouped together. For example,
        # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
        # be batched into a single group.
        group_by: ['alertname', 'cluster', 'service']

        # When a new group of alerts is created by an incoming alert, wait at
        # least 'group_wait' to send the initial notification.
        # This way ensures that you get multiple alerts for the same group that start
        # firing shortly after another are batched together on the first
        # notification.
        group_wait: 30s

        # When the first notification was sent, wait 'group_interval' to send a batch
        # of new alerts that started firing for that group.
        group_interval: 5m

        # If an alert has successfully been sent, wait 'repeat_interval' to
        # resend them.
        repeat_interval: 3h

        # A default receiver
        receiver: team-X-mails

        # All the above attributes are inherited by all child routes and can
        # overwritten on each.

        # The child route trees.
        routes:
        # This routes performs a regular expression match on alert labels to
        # catch alerts that are related to a list of services.
        - match_re:
            service: ^(foo1|foo2|baz)$
          receiver: team-X-mails
          # The service has a sub-route for critical alerts, any alerts
          # that do not match, i.e. severity != critical, fall-back to the
          # parent node and are sent to 'team-X-mails'
          routes:
          - match:
              severity: critical
            receiver: team-X-pager
        - match:
            service: files
          receiver: team-Y-mails

          routes:
          - match:
              severity: critical
            receiver: team-Y-pager

        # This route handles all alerts coming from a database service. If there's
        # no team to handle it, it defaults to the DB team.
        - match:
            service: database
          receiver: team-DB-pager
          # Also group alerts by affected database.
          group_by: [alertname, cluster, database]
          routes:
          - match:
              owner: team-X
            receiver: team-X-pager
          - match:
              owner: team-Y
            receiver: team-Y-pager


      # Inhibition rules allow to mute a set of alerts given that another alert is
      # firing.
      # We use this to mute any warning-level notifications if the same alert is
      # already critical.
      inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        # Apply inhibition if the alertname is the same.
        equal: ['alertname', 'cluster', 'service']


      receivers:
      - name: 'team-X-mails'
        email_configs:
        - to: 'team-X+alerts@example.org'

      - name: 'team-X-pager'
        email_configs:
        - to: 'team-X+alerts-critical@example.org'
        pagerduty_configs:
        - service_key: <team-X-key>

      - name: 'team-Y-mails'
        email_configs:
        - to: 'team-Y+alerts@example.org'

      - name: 'team-Y-pager'
        pagerduty_configs:
        - service_key: <team-Y-key>

      - name: 'team-DB-pager'
        pagerduty_configs:
        - service_key: <team-DB-key>
      - name: 'team-X-hipchat'
        hipchat_configs:
        - auth_token: <auth_token>
          room_id: 85
          message_format: html
          notify: true
    force: yes
    dest: /etc/alertmanager/config.yml
  register: updatealertmanager

- name: Creates directory /var/lib/prometheus-data/alertmanager
  file: path=/var/lib/prometheus-data/alertmanager state=directory

# - name: Restart a Alert Manager
#   docker_container:
#     name: alertmanager
#     restart_policy: always
#     image: prom/alertmanager:latest
#     command: "-config.file=/etc/alertmanager/config.yml -storage.path=/alertmanager"
#     state: started
#     labels:
#       org.label-schema.group: monitoring
#     volumes:
#      - "/var/lib/prometheus-data/alertmanager:/alertmanager"
#      - "/etc/alertmanager:/etc/alertmanager"
#     ports:
#     - "9093:9093"

- name: Creates directory /var/lib/prometheus-data/grafana
  file: path=/var/lib/prometheus-data/grafana state=directory

- name: Restart a Grafana
  docker_container:
    name: grafana
    restart_policy: always
    image: grafana/grafana:latest
    state: started
    labels:
      org.label-schema.group: monitoring
    volumes:
     - "/var/lib/prometheus-data/grafana:/var/lib/grafana"
    ports:
    - "3000:3000"
    env:
        GF_SECURITY_ADMIN_USER: admin
        GF_SECURITY_ADMIN_PASSWORD: changeme
        GF_USERS_ALLOW_SIGN_UP: "false"
